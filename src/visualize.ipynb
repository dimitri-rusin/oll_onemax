{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import inspectify\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objs as go\n",
    "import sqlite3\n",
    "import sqlite3\n",
    "import sqlite3\n",
    "\n",
    "def load_config_data(db_path):\n",
    "  loaded_config = {}\n",
    "  try:\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "      cursor = conn.cursor()\n",
    "      cursor.execute(\"SELECT key, value FROM CONFIG\")\n",
    "      rows = cursor.fetchall()\n",
    "\n",
    "    # Process each row to infer the type and construct a nested dictionary\n",
    "    for key, value in rows:\n",
    "      # Infer the type\n",
    "      if value.isdigit():\n",
    "        parsed_value = int(value)\n",
    "      elif all(char.isdigit() or char == '.' for char in value):\n",
    "        try:\n",
    "          parsed_value = float(value)\n",
    "        except ValueError:\n",
    "          parsed_value = value\n",
    "      elif value.startswith('{') and value.endswith('}'):\n",
    "        try:\n",
    "          # Attempt to parse as a dictionary\n",
    "          parsed_value = ast.literal_eval(value)\n",
    "        except (ValueError, SyntaxError):\n",
    "          # If parsing fails, keep the original value\n",
    "          parsed_value = value\n",
    "      else:\n",
    "        parsed_value = value\n",
    "\n",
    "      # Create nested dictionaries based on key structure\n",
    "      key_parts = key.split('__')\n",
    "      d = loaded_config\n",
    "      for part in key_parts[:-1]:\n",
    "        if part not in d:\n",
    "          d[part] = {}\n",
    "        d = d[part]\n",
    "      d[key_parts[-1]] = parsed_value\n",
    "  except sqlite3.Error:\n",
    "    # If the CONFIG table doesn't exist or any other SQL error occurs\n",
    "    loaded_config = {}\n",
    "\n",
    "  return loaded_config\n",
    "\n",
    "def load_configs_from_folder(folder_path):\n",
    "  configs = []\n",
    "  for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".db\"):\n",
    "      db_path = os.path.join(folder_path, file)\n",
    "      config = load_config_data(db_path)\n",
    "      config['db_path'] = db_path\n",
    "      configs.append(config)\n",
    "  return configs\n",
    "\n",
    "def format_value_for_expression(value):\n",
    "  if isinstance(value, str):\n",
    "    # Add quotes around strings\n",
    "    return f\"\\\"{value}\\\"\"\n",
    "  return value\n",
    "\n",
    "def match_config_with_filter(config, filter_expr):\n",
    "  for key, value in filter_expr.items():\n",
    "    if isinstance(value, dict):\n",
    "      # Recursive call for nested dictionaries\n",
    "      if key not in config or not match_config_with_filter(config[key], value):\n",
    "        return False\n",
    "    elif isinstance(value, list):\n",
    "      # Handle lists of expressions\n",
    "      for i, expr in enumerate(value):\n",
    "        if i >= len(config.get(key, [])):\n",
    "          return False\n",
    "        config_value = format_value_for_expression(config[key][i])\n",
    "        expression = expr.replace(\"{}\", str(config_value))\n",
    "        condition = eval(expression)\n",
    "        assert type(condition) == bool, f\"Filter {key}:{expression} must express a bool.\"\n",
    "        if not condition:\n",
    "          return False\n",
    "    else:\n",
    "      # Handle individual expressions\n",
    "      config_value = format_value_for_expression(config.get(key))\n",
    "      expression = value.replace(\"{}\", str(config_value))\n",
    "      condition = eval(expression)\n",
    "      assert type(condition) == bool, f\"Filter {key}:{expression} must express a bool.\"\n",
    "      if not condition:\n",
    "        return False\n",
    "  return True\n",
    "\n",
    "def filter_configs(configs, filter_expr):\n",
    "  matching_db_paths = []\n",
    "  for config in configs:\n",
    "    if match_config_with_filter(config, filter_expr):\n",
    "      matching_db_paths.append(config.get('db_path'))\n",
    "  return matching_db_paths\n",
    "\n",
    "def load_policy_performance_data(db_path, xaxis_choice, yaxis_choice):\n",
    "  conn = sqlite3.connect(db_path)\n",
    "  cursor = conn.cursor()\n",
    "\n",
    "  # Execute SQL query based on x-axis choice\n",
    "  cursor.execute(f'SELECT policy_id, {xaxis_choice} FROM CONSTRUCTED_POLICIES WHERE policy_id >= 1')\n",
    "  training_data = cursor.fetchall()\n",
    "\n",
    "  try:\n",
    "    cursor.execute('SELECT policy_id, num_training_episodes, num_total_function_evaluations, num_total_timesteps FROM CONSTRUCTED_POLICIES WHERE policy_id >= 1')\n",
    "    rows = cursor.fetchall()\n",
    "    policy_id_to_x_values = {policy_id: {column_name: value for column_name, value in zip(['num_training_episodes', 'num_total_function_evaluations', 'num_total_timesteps'], row)}\n",
    "                 for policy_id, *row in rows}\n",
    "  except sqlite3.OperationalError:\n",
    "    cursor.execute('SELECT policy_id, num_training_episodes FROM CONSTRUCTED_POLICIES WHERE policy_id >= 1')\n",
    "    rows = cursor.fetchall()\n",
    "    policy_id_to_x_values = {policy_id: {'num_training_episodes': num_training_episodes}\n",
    "                 for policy_id, num_training_episodes in rows}\n",
    "\n",
    "  avg_function_evaluations, std_dev_evaluations = [], []\n",
    "  for policy_id, _ in training_data:\n",
    "    cursor.execute(f'SELECT {yaxis_choice} FROM EVALUATION_EPISODES WHERE policy_id = ?', (policy_id,))\n",
    "    evaluations = [e[0] for e in cursor.fetchall()]\n",
    "    assert evaluations[0] is not None, f\"The database {db_path} has a table EVALUATION_EPISODES with a cell of column {yaxis_choice} that is NULL!\"\n",
    "    num_evaluation_episodes = len(evaluations)  # Assuming number of episodes is length of evaluations\n",
    "\n",
    "    avg_evaluations = sum(evaluations) / len(evaluations) if evaluations else None\n",
    "    std_dev = math.sqrt(sum((e - avg_evaluations) ** 2 for e in evaluations) / len(evaluations)) if evaluations else 0\n",
    "    avg_function_evaluations.append(avg_evaluations if avg_evaluations is not None else 0)\n",
    "    std_dev_evaluations.append(std_dev)\n",
    "\n",
    "  policy_ids, num_training_timesteps_or_num_training_fes = zip(*training_data) if training_data else ([], [])\n",
    "\n",
    "  cursor.execute(f'SELECT {yaxis_choice} FROM EVALUATION_EPISODES WHERE policy_id = -1')\n",
    "  baseline_evaluations = [e[0] for e in cursor.fetchall()]\n",
    "  baseline_avg_length = sum(baseline_evaluations) / len(baseline_evaluations)\n",
    "  baseline_variance = sum((e - baseline_avg_length) ** 2 for e in baseline_evaluations) / (len(baseline_evaluations) - 1) if len(baseline_evaluations) > 1 else 0\n",
    "  baseline_std_dev = math.sqrt(baseline_variance)\n",
    "\n",
    "  baseline_upper_bound = [baseline_avg_length + baseline_std_dev] * len(num_training_timesteps_or_num_training_fes)\n",
    "  baseline_lower_bound = [baseline_avg_length - baseline_std_dev] * len(num_training_timesteps_or_num_training_fes)\n",
    "\n",
    "  data = [\n",
    "    go.Scatter(x=num_training_timesteps_or_num_training_fes, y=avg_function_evaluations, mode='lines+markers', name='#FEs until optimum', line=dict(color='blue', width=4)),\n",
    "    go.Scatter(x=num_training_timesteps_or_num_training_fes, y=[avg + std for avg, std in zip(avg_function_evaluations, std_dev_evaluations)], mode='lines', line=dict(color='rgba(173,216,230,0.2)'), name='Upper Bound (Mean + Std. Dev.)'),\n",
    "    go.Scatter(x=num_training_timesteps_or_num_training_fes, y=[avg - std for avg, std in zip(avg_function_evaluations, std_dev_evaluations)], mode='lines', fill='tonexty', line=dict(color='rgba(173,216,230,0.2)'), name='Lower Bound (Mean - Std. Dev.)'),\n",
    "    go.Scatter(x=[min(num_training_timesteps_or_num_training_fes), max(num_training_timesteps_or_num_training_fes)] if num_training_timesteps_or_num_training_fes else [0], y=[baseline_avg_length, baseline_avg_length], mode='lines', name='Theory: ‚àö(ùëõ/(ùëõ ‚àí ùëì(ùë•)))', line=dict(color='orange', width=2, dash='dash')),\n",
    "    go.Scatter(x=num_training_timesteps_or_num_training_fes, y=baseline_upper_bound, mode='lines', line=dict(color='rgba(255, 165, 0, 0.2)'), name='Upper Bound (Baseline Variance)'),\n",
    "    go.Scatter(x=num_training_timesteps_or_num_training_fes, y=baseline_lower_bound, mode='lines', fill='tonexty', line=dict(color='rgba(255, 165, 0, 0.2)'), name='Lower Bound (Baseline Variance)'),\n",
    "  ]\n",
    "\n",
    "  conn.close()\n",
    "  return data\n",
    "\n",
    "def policy_performance(db_path, xaxis_choice, yaxis_choice):\n",
    "  data = load_policy_performance_data(db_path, xaxis_choice, yaxis_choice)\n",
    "  # Define the layout with larger dimensions and enhanced appearance\n",
    "  layout = go.Layout(\n",
    "    titlefont=dict(size=24),  # Bigger title font size\n",
    "    xaxis=dict(\n",
    "      title=xaxis_choice.replace('_', ' ').title(),\n",
    "      titlefont=dict(size=18),  # Bigger axis title font size\n",
    "      tickfont=dict(size=14),  # Bigger tick labels font size\n",
    "      gridcolor='lightgrey',  # Grid color\n",
    "      gridwidth=2,  # Grid line width\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "      title='#FEs until optimum',\n",
    "      titlefont=dict(size=18),  # Bigger axis title font size\n",
    "      tickfont=dict(size=14),  # Bigger tick labels font size\n",
    "      gridcolor='lightgrey',  # Grid color\n",
    "      gridwidth=2,  # Grid line width\n",
    "    ),\n",
    "    font=dict(family='Courier New, monospace', size=18, color='RebeccaPurple'),\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(245, 245, 245, 1)',\n",
    "    width=1100,  # Width of the figure\n",
    "    height=600,  # Height of the figure\n",
    "    margin=dict(l=50, r=50, b=100, t=100, pad=4),  # Margins to prevent cutoff\n",
    "    showlegend=False,  # This will remove the legend\n",
    "  )\n",
    "\n",
    "  fig = go.Figure(data=data, layout=layout)\n",
    "  fig.show()\n",
    "\n",
    "def get_policy_id_for_timesteps(db_path, total_timesteps):\n",
    "  try:\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "      cursor = conn.cursor()\n",
    "      # SQL query to fetch policy_id based on the total timesteps\n",
    "      cursor.execute('SELECT policy_id FROM CONSTRUCTED_POLICIES WHERE num_total_timesteps = ?', (total_timesteps,))\n",
    "      result = cursor.fetchone()\n",
    "      return result[0] if result else None\n",
    "  except sqlite3.Error as e:\n",
    "    print(f\"SQLite error: {e}\")\n",
    "    return None\n",
    "\n",
    "def generate_fitness_lambda_plot(db_path, policy_total_timesteps, yaxis_choice):\n",
    "\n",
    "  conn = sqlite3.connect(db_path)\n",
    "  cursor = conn.cursor()\n",
    "\n",
    "  # Fetch baseline fitness-lambda data (policy_id = -1)\n",
    "  cursor.execute('SELECT fitness, lambda_minus_one FROM POLICY_DETAILS WHERE policy_id = -1')\n",
    "  baseline_fitness_lambda_data = cursor.fetchall()\n",
    "\n",
    "  baseline_curve = go.Scatter(\n",
    "    x=[d[0] for d in baseline_fitness_lambda_data],\n",
    "    y=[d[1] + 1 for d in baseline_fitness_lambda_data],\n",
    "    mode='lines+markers',\n",
    "    name='Baseline Fitness-Lambda',\n",
    "    line=dict(color='orange', width=4)\n",
    "  )\n",
    "\n",
    "  policy_id = get_policy_id_for_timesteps(db_path, policy_total_timesteps)\n",
    "  assert policy_id is not None, f\"The number of total timesteps {policy_total_timesteps:,} has resulted in a non-existing policy ID!\"\n",
    "\n",
    "  # Fetch mean and variance of initial fitness for the specified policy\n",
    "  cursor.execute('SELECT mean_initial_fitness, variance_initial_fitness FROM CONSTRUCTED_POLICIES WHERE policy_id = ?', (policy_id,))\n",
    "  fitness_stats = cursor.fetchone()\n",
    "  mean_initial_fitness = std_dev_initial_fitness = None\n",
    "  if fitness_stats and fitness_stats[0]:\n",
    "    mean_initial_fitness = fitness_stats[0]\n",
    "    variance_initial_fitness = fitness_stats[1]\n",
    "    std_dev_initial_fitness = math.sqrt(variance_initial_fitness)\n",
    "\n",
    "  # Fetch fitness-lambda data for the specified policy\n",
    "  cursor.execute('SELECT fitness, lambda_minus_one FROM POLICY_DETAILS WHERE policy_id = ?', (policy_id,))\n",
    "  fitness_lambda_data = cursor.fetchall()\n",
    "\n",
    "  selected_policy_curve = go.Scatter(\n",
    "    x=[d[0] for d in fitness_lambda_data],\n",
    "    y=[d[1] + 1 for d in fitness_lambda_data],\n",
    "    mode='lines+markers',\n",
    "    name=f'Fitness-Lambda Policy {policy_id}',\n",
    "    line=dict(color='blue', width=4)\n",
    "  )\n",
    "\n",
    "  data = [baseline_curve, selected_policy_curve]\n",
    "\n",
    "  # Adding shaded area for variance if available\n",
    "  if mean_initial_fitness is not None:\n",
    "    upper_bound = go.Scatter(\n",
    "      x=[mean_initial_fitness + std_dev_initial_fitness] * 2,\n",
    "      y=[0, max([d[1] + 1 for d in fitness_lambda_data])],\n",
    "      mode='lines',\n",
    "      line=dict(width=0),\n",
    "      showlegend=False\n",
    "    )\n",
    "    lower_bound = go.Scatter(\n",
    "      x=[mean_initial_fitness - std_dev_initial_fitness] * 2,\n",
    "      y=[0, max([d[1] + 1 for d in fitness_lambda_data])],\n",
    "      mode='lines',\n",
    "      fill='tonexty',\n",
    "      fillcolor='rgba(0, 255, 0, 0.2)',\n",
    "      line=dict(width=0),\n",
    "      name='Variance Initial Fitness'\n",
    "    )\n",
    "    mean_line = go.Scatter(\n",
    "      x=[mean_initial_fitness, mean_initial_fitness],\n",
    "      y=[0, max([d[1] + 1 for d in fitness_lambda_data])],\n",
    "      mode='lines',\n",
    "      name=f'Mean Initial Fitness',\n",
    "      line=dict(color='green', width=2, dash='dot')\n",
    "    )\n",
    "    data.extend([upper_bound, lower_bound, mean_line])\n",
    "\n",
    "  layout = go.Layout(\n",
    "    title=f'Fitness-Lambda Assignment for Policy {policy_id}',\n",
    "    xaxis=dict(title='Fitness'),\n",
    "    yaxis=dict(title='Lambda'),\n",
    "    font=dict(family='Courier New, monospace', size=18, color='RebeccaPurple'),\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(245, 245, 245, 1)'\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  # ================= Print scalar info about specified policy: ====================================\n",
    "  cursor.execute(f'SELECT policy_id, {xaxis_choice} FROM CONSTRUCTED_POLICIES WHERE policy_id = ?', (policy_id,))\n",
    "  training_data = cursor.fetchone()\n",
    "  assert len(training_data) > 0, f\"Policy ID {policy_id} missing!\"\n",
    "  _, num_training_timesteps_or_num_training_fes = training_data\n",
    "  cursor.execute(f'SELECT {yaxis_choice} FROM EVALUATION_EPISODES WHERE policy_id = ?', (policy_id,))\n",
    "  evaluations = [e[0] for e in cursor.fetchall()]\n",
    "  avg_evaluations = sum(evaluations) / len(evaluations) if evaluations else None\n",
    "  std_dev = math.sqrt(sum((e - avg_evaluations) ** 2 for e in evaluations) / len(evaluations)) if evaluations else 0\n",
    "\n",
    "  cursor.execute(f'SELECT {yaxis_choice} FROM EVALUATION_EPISODES WHERE policy_id = -1')\n",
    "  baseline_evaluations = [e[0] for e in cursor.fetchall()]\n",
    "  baseline_avg_length = sum(baseline_evaluations) / len(baseline_evaluations)\n",
    "  baseline_variance = sum((e - baseline_avg_length) ** 2 for e in baseline_evaluations) / (len(baseline_evaluations) - 1) if len(baseline_evaluations) > 1 else 0\n",
    "  baseline_std_dev = math.sqrt(baseline_variance)\n",
    "\n",
    "\n",
    "\n",
    "  print(\"Policy ID:\", policy_id)\n",
    "  print(\"Y axis name:\", yaxis_choice)\n",
    "  print(\"Y axis:\", \"{:,}\".format(num_training_timesteps_or_num_training_fes))\n",
    "  print(\"Y axis (Mean):\", avg_evaluations)\n",
    "  print(\"Y axis (Mean - Stddev):\", avg_evaluations - std_dev)\n",
    "  print(\"Y axis (Mean + Stddev):\", avg_evaluations + std_dev)\n",
    "  print(\"Baseline y axis (Mean):\", baseline_avg_length)\n",
    "  print(\"Baseline y axis (Mean - Stddev):\", baseline_avg_length - baseline_std_dev)\n",
    "  print(\"Baseline y axis (Mean + Stddev):\", baseline_avg_length + baseline_std_dev)\n",
    "  # ================= PRINT END ====================================\n",
    "\n",
    "  conn.close()\n",
    "  fig = go.Figure(data=data, layout=layout)\n",
    "  fig.show()\n",
    "\n",
    "def print_matching(db_folder_path, filter_expression):\n",
    "  configs = load_configs_from_folder(db_folder_path)\n",
    "  matching_db_paths = filter_configs(configs, filter_expression)\n",
    "  for path in matching_db_paths:\n",
    "    print(path)\n",
    "\n",
    "def display_config_as_dataframe(db_path):\n",
    "  try:\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "      df = pd.read_sql_query(\"SELECT key, value FROM CONFIG\", conn)\n",
    "  except sqlite3.Error as e:\n",
    "    print(f\"SQLite error: {e}\")\n",
    "    return None\n",
    "\n",
    "  def format_value(value):\n",
    "    \"\"\"Format numerical values with commas.\"\"\"\n",
    "    try:\n",
    "      if isinstance(value, (int, float)):\n",
    "        return \"{:,}\".format(value)\n",
    "      if isinstance(value, str):\n",
    "        if value.isdigit():\n",
    "          return \"{:,}\".format(int(value))\n",
    "        # Attempt to convert to float for strings like '123.45'\n",
    "        try:\n",
    "          return \"{:,}\".format(float(value))\n",
    "        except ValueError:\n",
    "          pass\n",
    "    except (ValueError, TypeError):\n",
    "      pass\n",
    "    return value\n",
    "\n",
    "  def unfold_dict(prefix, d, rows):\n",
    "    \"\"\"Recursive function to unfold nested dictionaries.\"\"\"\n",
    "    for key, value in d.items():\n",
    "      new_key = f\"{prefix}__{key}\" if prefix else key\n",
    "      if isinstance(value, dict):\n",
    "        unfold_dict(new_key, value, rows)\n",
    "      else:\n",
    "        formatted_value = format_value(value)\n",
    "        rows.append({'key': new_key, 'value': formatted_value})\n",
    "\n",
    "  # Process each row and unfold nested dictionaries\n",
    "  new_rows = []\n",
    "  for _, row in df.iterrows():\n",
    "    try:\n",
    "      value = ast.literal_eval(row['value'])\n",
    "      if isinstance(value, dict):\n",
    "        unfold_dict(row['key'], value, new_rows)\n",
    "      else:\n",
    "        formatted_value = format_value(value)\n",
    "        new_rows.append({'key': row['key'], 'value': formatted_value})\n",
    "    except (ValueError, SyntaxError):\n",
    "      # Format value if it's a number, keep as is otherwise\n",
    "      formatted_value = format_value(row['value'])\n",
    "      new_rows.append({'key': row['key'], 'value': formatted_value})\n",
    "\n",
    "  # Create a new DataFrame from the processed rows and set 'key' as the index\n",
    "  new_df = pd.DataFrame(new_rows).set_index('key')\n",
    "\n",
    "  return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_folder_path = '../computed/cirrus/'\n",
    "filter_expression = {\n",
    "  \"max_training_timesteps\": \"{} == {}\",\n",
    "  \"ppo\": {\n",
    "    \"n_steps\": \"{} == {}\",\n",
    "    \"policy\": \"{} == {}\",\n",
    "    \"batch_size\": \"{} == 100\",\n",
    "    \"gamma\": \"{} == {}\",\n",
    "    \"gae_lambda\": \"{} <= 0.98\",\n",
    "    \"vf_coef\": \"{} == {}\",\n",
    "    \"net_arch\": [\n",
    "      \"{} == {}\",\n",
    "      \"{} == {}\",\n",
    "    ],\n",
    "    \"learning_rate\": \"{} == {}\",\n",
    "    \"clip_range\": \"{} == {}\",\n",
    "    \"n_epochs\": \"{} == {}\",\n",
    "    \"ent_coef\": \"{} == {}\",\n",
    "  },\n",
    "  \"n\": \"{} >= 40\",\n",
    "  \"num_timesteps_per_evaluation\": \"{} == {}\",\n",
    "  \"reward_type\": \"{} == {}\",\n",
    "  \"num_evaluation_episodes\": \"{} == {}\",\n",
    "  \"action_type\": \"{} == {}\",\n",
    "  \"num_lambdas\": \"{} == {}\",\n",
    "  \"random_seed\": \"{} == {}\",\n",
    "  \"probability_of_closeness_to_optimum\": \"{} == {}\",\n",
    "  \"state_type\": \"{} == {}\",\n",
    "}\n",
    "\n",
    "print_matching(db_folder_path, filter_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e2f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"../computed/data/shadily.db\"\n",
    "display_config_as_dataframe(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis_choice = \"num_total_timesteps\"\n",
    "yaxis_choice = \"num_function_evaluations\"\n",
    "yaxis_choice = \"episode_length\"\n",
    "policy_performance(db_path, xaxis_choice, yaxis_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_total_timesteps = 2\n",
    "generate_fitness_lambda_plot(db_path, policy_total_timesteps, yaxis_choice)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
